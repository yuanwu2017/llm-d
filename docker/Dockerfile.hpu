# Copyright (C) 2025 Habana Labs, Ltd. an Intel Company
# SPDX-License-Identifier: Apache-2.0

# Parameterize base image components
ARG DOCKER_URL=vault.habana.ai/gaudi-docker
ARG VERSION=1.22.0
ARG BASE_NAME=ubuntu22.04
ARG PT_VERSION=2.7.1
ARG REVISION=latest
ARG REPO_TYPE=habanalabs

FROM ${DOCKER_URL}/${VERSION}/${BASE_NAME}/${REPO_TYPE}/pytorch-installer-${PT_VERSION}:${REVISION}

# Parameterize commit/branch for vllm-project & vllm-gaudi checkout
ENV OMPI_MCA_btl_vader_single_copy_mechanism=none

RUN apt update && \
    apt install -y gettext moreutils jq && \
    ln -sf /usr/bin/python3 /usr/bin/python
WORKDIR /root

ENV VLLM_PATH=/workspace/vllm-project
ENV VLLM_PATH2=/workspace/vllm-gaudi

RUN echo "dash dash/sh boolean false" | debconf-set-selections && \
    DEBIAN_FRONTEND=noninteractive dpkg-reconfigure dash
ENV ENV=~/.profile

# --- START: COMBINED RUN COMMAND ---
RUN \
    # Clone vllm-gaudi and get the commit hash
    set -e && \
    mkdir -p $VLLM_PATH2 && \
    git clone https://github.com/vllm-project/vllm-gaudi.git $VLLM_PATH2 && \
    cd $VLLM_PATH2 && \
    VLLM_COMMIT_HASH=$(git show "origin/vllm/last-good-commit-for-vllm-gaudi:VLLM_STABLE_COMMIT" 2>/dev/null) && \
    echo "Found vLLM commit hash: ${VLLM_COMMIT_HASH}" && \
    \
    # Clone vllm-project, check out the specific commit, and install
    mkdir -p $VLLM_PATH && \
    git clone https://github.com/vllm-project/vllm.git $VLLM_PATH && \
    cd $VLLM_PATH && \
    git remote add upstream https://github.com/vllm-project/vllm.git && \
    git fetch upstream --tags || true && \
    git checkout ${VLLM_COMMIT_HASH} && \
    pip install -r <(sed '/^[torch]/d' requirements/build.txt) && \
    VLLM_TARGET_DEVICE=empty pip install . && \
    \
    # Install vllm-gaudi
    cd $VLLM_PATH2 && \
    VLLM_TARGET_DEVICE=hpu pip install -v . && \
    python install_nixl.py
# --- END: COMBINED RUN COMMAND ---

# Install additional Python packages
RUN pip install datasets && \
    pip install pandas && pip install lm-eval lm-eval[api] && \
    pip install pytest pytest_asyncio pytest-timeout

# Copy utility scripts and configuration
WORKDIR /workspace
RUN ln -s /workspace/vllm/tests /workspace/tests \
    && ln -s /workspace/vllm/examples /workspace/examples \
    && ln -s /workspace/vllm/benchmarks /workspace/benchmarks
